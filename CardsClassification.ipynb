{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNRuR9Bt0p85ZpyEJ4KhV+a"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"I-rtrYPtCUpc"},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"code","source":["import json\n","token = {\"username\":\"\",\"key\":\"\"}#使用你自己的用户和密钥 Use your own username and key\n","with open('/content/kaggle.json', 'w') as file:\n","  json.dump(token, file)\n","!mkdir -p ~/.kaggle\n","!cp /content/kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json\n","!kaggle config set -n path -v /content"],"metadata":{"id":"VB3HqC_CCdM4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!kaggle datasets download -d gpiosenka/cards-image-datasetclassification"],"metadata":{"id":"b-XtoJgoCgrf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!unzip '/content/datasets/gpiosenka/cards-image-datasetclassification/cards-image-datasetclassification.zip'"],"metadata":{"id":"_jdAClYsCiYI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","from torch.utils.data import Dataset \n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch import optim\n","from torch.utils.data import DataLoader\n","from torchvision import transforms, models, datasets\n","import time\n","import torch as t \n","from torchvision import transforms as T \n","from PIL import Image  \n","from torch.optim import lr_scheduler"],"metadata":{"id":"teo1q23zCjrd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Cards(Dataset):\n","  def __init__(self, train = True, mode = 'train\\n'):\n","      \n","    data_dir = '.'#相对路径就能运行，好家伙\n","    fname = os.path.join(data_dir, 'cards.csv')\n","    with open(fname, 'r') as f:\n","        lines = f.readlines()[1:] \n","    self.imgs = []\n","    \n","    for i in lines:\n","        if i.split(',')[4] == mode:\n","            self.imgs.append(i.split(',')) \n","    for line in self.imgs:\n","      if line[1] == 'train/ace of clubs/output':\n","          print('Pre handle the data')\n","          self.imgs.remove(line)\n","    normalize = T.Normalize(mean = [0.5, 0.5, 0.5], std = [0.5, 0.5, 0.5])\n","    if not train:\n","        # 验证集或测试集\n","        self.transform = T.Compose([\n","            T.Resize(224),#最短边224像素\n","            T.CenterCrop(224),#中心裁剪\n","            T.ToTensor(),#转成tensor\n","            normalize#归一化\n","        ])\n","    else:\n","        # 训练集，做数据增广\n","        self.transform = T.Compose([\n","            T.Resize(224),\n","            T.RandomResizedCrop(224),\n","            T.RandomHorizontalFlip(),#按概率水平翻转\n","            T.ToTensor(),\n","            normalize\n","        ])\n","\n","  def __getitem__(self, index):\n","    img_line = self.imgs[index]\n","    img_path = './'+img_line[1]\n","    label = int(img_line[0])\n","    data = Image.open(img_path)\n","    data = self.transform(data)\n","    return data, label\n","\n","  def __len__(self):\n","    return len(self.imgs)"],"metadata":{"id":"-RaJ4xmBCll6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class basic_block(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(basic_block, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=1, stride=1, padding=0)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","\n","    def forward(self, x):\n","        y = F.relu(self.conv1(x))\n","        y = self.bn1(y)\n","        y = self.conv2(y)\n","        y = self.bn2(y)\n","        return F.relu(x + y)\n","\n","class basic_block2(nn.Module):\n","    def __init__(self,in_channels,out_channels):# 3-64 64-128 128-256\n","        super(basic_block2, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels,out_channels,kernel_size=1,stride=2,padding=0)\n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","        self.conv2 = nn.Conv2d(in_channels,out_channels,kernel_size=3,stride=2,padding=1)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","        self.conv3 = nn.Conv2d(out_channels,out_channels,kernel_size=1,stride=1,padding=0)\n","        self.bn3 = nn.BatchNorm2d(out_channels)\n","    def forward(self, x):\n","        z = self.conv1(x)\n","        z = self.bn1(z)\n","        y = F.relu(self.bn2(self.conv2(x)))\n","        y = self.conv3(y)\n","        y = self.bn3(y)\n","        return F.relu(y+z)\n"],"metadata":{"id":"AhM9n0LZCoXv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Resnet18(nn.Module):\n","    '''按照网络结构图直接连接，确定好通道数量就可以'''\n","\n","    def __init__(self):\n","        super(Resnet18, self).__init__()\n","        self.conv1 = nn.Sequential(\n","            nn.Conv2d(3,64,kernel_size=7,stride=2,padding=3,bias=False),\n","            nn.BatchNorm2d(64),\n","            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","        )\n","        self.res2 = basic_block(64, 64)\n","        self.res3 = basic_block(64, 64)\n","        self.res4 = basic_block2(64, 128)\n","        self.res5 = basic_block(128, 128)\n","        self.res6 = basic_block2(128, 256)\n","        self.res7 = basic_block(256, 256)\n","        self.res8 = basic_block2(256, 512)\n","        self.res9 = basic_block(512, 512)\n","        self.avgpool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n","        self.fc = nn.Linear(512, 53)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.res2(x)\n","        x = self.res3(x)\n","        x = self.res4(x)\n","        x = self.res5(x)\n","        x = self.res6(x)\n","        x = self.res7(x)\n","        x = self.res8(x)\n","        x = self.res9(x)\n","        x = self.avgpool(x)\n","        x = x.reshape(x.shape[0], -1)\n","        x = self.fc(x)\n","        return x"],"metadata":{"id":"WZSk2bt_CqhW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def main():  # dataset_1 dataset-resized\n","    train_data = Cards(train=True,mode = 'train\\n')\n","    test_data = Cards(train=False,mode = 'test\\n')\n","    train_loader = DataLoader(\n","        train_data,\n","        batch_size=128,\n","        shuffle=True,\n","        num_workers=0\n","    )\n","    test_loader = DataLoader(\n","        test_data,\n","        batch_size=128,\n","        shuffle=False,\n","        num_workers=0\n","    )\n","    model = AlexNet()\n","    print(model)\n","    device = torch.device('cuda:0')\n","    model = model.to(device)\n","    criteon = nn.CrossEntropyLoss().to(device)#交叉熵损失\n","    optimizer = optim.SGD(model.parameters(), lr=0.01)#优化器\n","    scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[20], gamma=0.1)\n","    best_val_acc = 0\n","    for epoch in range(50):\n","        model.train()\n","        since = time.time()\n","        for x, label in train_loader:\n","            x, label = x.to(device), label.to(device)#传给GPU\n","            logits = model(x)#返回值\n","            loss = criteon(logits, label)#计算损失\n","            optimizer.zero_grad()#梯度清零\n","            loss.backward()\n","            optimizer.step()\n","        print('Epoch: ', epoch, '训练集 loss: ', loss.item())#item是转成数字\n","        model.eval()\n","        with torch.no_grad():\n","            # 测试集\n","            total_correct = 0\n","            total_num = 0\n","            for x, label in test_loader:\n","                x, label = x.to(device), label.to(device)\n","                logits = model(x)\n","                loss = criteon(logits, label)\n","                pred = logits.argmax(dim=1)#获得每行最大值列号\n","                correct = torch.eq(pred, label).float().sum().item()\n","                total_correct += correct\n","                total_num += x.size(0)\n","            val_acc = total_correct / total_num\n","            if val_acc > best_val_acc:\n","                best_val_acc = val_acc\n","                torch.save(model.state_dict(), \"./model_parameter.pkl\")\n","            time_elapsed = time.time() - since\n","            print('Epoch: ', epoch, '测试集 loss: ', loss.item())#item是转成数字\n","            print('Epoch: ',epoch,' Training complete in {:.0f}min {:.0f}seconds'.format(time_elapsed // 60, time_elapsed % 60))\n","            timeCost = 'Training time {:.0f}min {:.0f}seconds'.format(time_elapsed // 60, time_elapsed % 60)\n","            print('Epoch: ',epoch, ' test acc: ', val_acc)\n","        scheduler.step()\n","    print('The best acc is '+ str(best_val_acc))\n"],"metadata":{"id":"vNljLl6HCxFg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["main()"],"metadata":{"id":"Z7bnBzzdCyqJ"},"execution_count":null,"outputs":[]}]}